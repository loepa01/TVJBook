{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5613e265",
   "metadata": {},
   "source": [
    "# 2. Small-scale ChatGPT - generování textu pomocí neuronových sítí"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f05718",
   "metadata": {},
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db8f1c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9b1360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c056da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = 'cpu'  # Force CPU for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67efa21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62639afd",
   "metadata": {},
   "source": [
    "# Generování jmen pomocí jednoduché RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26c18dc",
   "metadata": {},
   "source": [
    "## Příprava dat\n",
    "\n",
    "Databáze evropských jmen a příjmení: https://data.europa.eu/data/datasets/5bc35259634f41122d982759?locale=cs\n",
    "\n",
    "Složka /datasets/SeznamJmenCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "151d04e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 CSV files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3063,),\n",
       " array(['AADAR', 'BACH', 'CADEN', ..., 'TYMUR', 'TYRIAN', 'TYSON'],\n",
       "       shape=(3063,), dtype=object))"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "csv_files = glob.glob('datasets/SeznamJmenCR/Seznam_muzskych_jmen*.csv')\n",
    "dfs = [pd.read_csv(f, encoding='utf-8') for f in csv_files]\n",
    "print(f\"Loaded {len(dfs)} CSV files.\")\n",
    "\n",
    "jmena_muz_all = []\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    jmena = dfs[i][2:].values.flatten()\n",
    "    jmena = jmena[~pd.isna(jmena)]\n",
    "    jmena_muz_all = np.concatenate((jmena_muz_all, jmena))\n",
    "    \n",
    "jmena_muz_all.shape, jmena_muz_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "853c3a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 CSV files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((3937,),\n",
       " array(['AALIYAH', 'BABETA', 'CAITIR', ..., 'VRATISLAVA', 'VRINDAVANI',\n",
       "        'VRONA'], shape=(3937,), dtype=object))"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob.glob('datasets/SeznamJmenCR/Seznam_zenskych_jmen*.csv')\n",
    "dfs = [pd.read_csv(f, encoding='utf-8') for f in csv_files]\n",
    "print(f\"Loaded {len(dfs)} CSV files.\")\n",
    "\n",
    "jmena_zen_all = []\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    jmena = dfs[i][2:].values.flatten()\n",
    "    jmena = jmena[~pd.isna(jmena)]\n",
    "    jmena_zen_all = np.concatenate((jmena_zen_all, jmena))\n",
    "    \n",
    "jmena_zen_all.shape, jmena_zen_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "25f67a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 CSV files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((4296,),\n",
       " array(['AAGTE', 'BAAIKE', 'CAELESTIS', ..., 'TYRESE', 'TYSK', 'TYSKE'],\n",
       "       shape=(4296,), dtype=object))"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files = glob.glob('datasets/SeznamJmenCR/Seznam_rodove_neutralnich_jmen*.csv')\n",
    "dfs = [pd.read_csv(f, encoding='utf-8') for f in csv_files]\n",
    "print(f\"Loaded {len(dfs)} CSV files.\")\n",
    "\n",
    "jmena_rod_all = []\n",
    "\n",
    "for i in range(len(dfs)):\n",
    "    jmena = dfs[i][2:].values.flatten()\n",
    "    jmena = jmena[~pd.isna(jmena)]\n",
    "    jmena_rod_all = np.concatenate((jmena_rod_all, jmena))\n",
    "    \n",
    "jmena_rod_all.shape, jmena_rod_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "b5053dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11296,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jmena_all = np.concatenate((jmena_muz_all, jmena_zen_all, jmena_rod_all))\n",
    "jmena_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ab27cf22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11162,)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(jmena_all).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8001371b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AADAR'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jmena_all[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "effd303a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10100]\n"
     ]
    }
   ],
   "source": [
    "positions = np.where(jmena_all == 'SARA **')[0]\n",
    "print(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "2d872360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11331,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_csv('datasets/SeznamJmenCR/OpenData_-_Seznam_jmen_k_2025-05-31.csv', encoding='utf-8')\n",
    "jmena_typ2 = dfs.iloc[:, 0]\n",
    "jmena_all2 = dfs.iloc[:, 1]\n",
    "jmena_all2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a7a64908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11172,), (11172,))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jmena_all2, idx = np.unique(jmena_all2, return_index=True)\n",
    "jmena_typ2 = jmena_typ2[idx]\n",
    "jmena_all2.shape, jmena_typ2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa02a026",
   "metadata": {},
   "source": [
    "Vyčištění speciálních znaků"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3c5b471b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11172"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "jmena_all3 = []\n",
    "\n",
    "# Set vocab to all utf-8 printable characters\n",
    "vocab = list('`1234567890-=[];\\',./*-+.~!@#$%^&*()_+{}:\"|<>?')\n",
    "\n",
    "for jmeno in jmena_all2:\n",
    "    cleaned = ''.join([ch for ch in str(jmeno) if ch not in vocab])\n",
    "    first_seq = cleaned.split()[0] if cleaned.split() else ''\n",
    "    jmena_all3.append(first_seq)\n",
    "    \n",
    "jmena_all3 = np.array(jmena_all3)\n",
    "len(jmena_all3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0564d59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "positions = np.where(jmena_all3 == 'SARA **')[0]\n",
    "print(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d1b993e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 unique characters\n",
      "['\\n', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'i', 'Á', 'Â', 'Ä', 'Æ', 'Ç', 'É', 'Ë', 'Í', 'Ï', 'Ó', 'Ô', 'Ö', 'Ø', 'Ú', 'Û', 'Ü', 'Ý', 'Ć', 'Č', 'Ď', 'Ě', 'Ľ', 'Ł', 'Ň', 'Ř', 'Ş', 'Š', 'Ť', 'Ů', 'Ű', 'Ź', 'Ż', 'Ž', 'ʼ', '$']\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set('\\n'.join(jmena_all3)))\n",
    "\n",
    "# insert special starting character\n",
    "vocab.append('$')\n",
    "\n",
    "print(f'{len(vocab)} unique characters')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ce9b62eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ABCDEFGHIJKLMNOPQRSTUVWXYZiÁÂÄÆÇÉËÍÏÓÔÖØÚÛÜÝĆČĎĚĽŁŇŘŞŠŤŮŰŹŻŽʼ$\n"
     ]
    }
   ],
   "source": [
    "allowed_characters = ''.join(vocab)\n",
    "print(allowed_characters)\n",
    "n_letters = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cfb4db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    # return our out-of-vocabulary character if we encounter a letter unknown to our model\n",
    "    if letter not in allowed_characters:\n",
    "        return allowed_characters.find(\"_\")\n",
    "    else:\n",
    "        return allowed_characters.find(letter)\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "33b6c845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineToTensor('JAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd662d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1629642",
   "metadata": {},
   "source": [
    "# Generování textu pomocí character-level RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ea5b30",
   "metadata": {},
   "source": [
    "## Příprava dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e24940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt'\n",
    "path_to_file = 'datasets/shakespeare.txt'\n",
    "\n",
    "if not os.path.exists(path_to_file):\n",
    "    torch.hub.download_url_to_file(url, path_to_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aeeba8",
   "metadata": {},
   "source": [
    "### Prozkoumání textu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf81804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 1115394 characters\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
    "# length of text is the number of characters in it\n",
    "print(f'Length of text: {len(text)} characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8566ca86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25182095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n",
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf81ea",
   "metadata": {},
   "source": [
    "### Zpracování textu na tokeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee94e120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    }
   ],
   "source": [
    "allowed_characters = ''.join(vocab)\n",
    "print(allowed_characters)\n",
    "n_letters = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d4829d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    # return our out-of-vocabulary character if we encounter a letter unknown to our model\n",
    "    if letter not in allowed_characters:\n",
    "        return allowed_characters.find(\"_\")\n",
    "    else:\n",
    "        return allowed_characters.find(letter)\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da07c73",
   "metadata": {},
   "source": [
    "## Zdroje"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d42db7",
   "metadata": {},
   "source": [
    "https://docs.pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/text_generation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
